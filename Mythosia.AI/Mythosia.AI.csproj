<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>netstandard2.1</TargetFramework>
    <Nullable>enable</Nullable>
  </PropertyGroup>

  <ItemGroup>
    <InternalsVisibleTo Include="Mythosia.AI.Test" />
  </ItemGroup>


	<PropertyGroup>
		<VersionPrefix>4.5.0</VersionPrefix>

		<Company>Mythosia</Company>
		<PackageTags>AI; Grok; xAI; Grok4; Grok3; Gpt5; Gpt5.1; Gpt5.2; Gpt5.2Codex; Claude Opus 4.6; Claude Sonnet 4.6; Claude Opus 4.5; Claude Sonnet 4.5; Claude Haiku 4.5; ChatGpt; Claude; DeepSeek; Sonar; Gemini; Gemini2.5; Gemini3; Reasoning; Multi modal;</PackageTags>
		<Authors>JJW</Authors>
		<Description>
## What's New in v4.5.0

### Structured Output with Auto-Recovery
- `GetCompletionAsync&lt;T&gt;()` — Deserialize LLM responses directly into C# POCOs
- Auto-recovery retry: invalid JSON triggers correction prompt to the LLM (configurable retries)
- `StructuredOutputException` with rich diagnostics (raw responses, parse error, attempt count, schema)
- OpenAI-strict JSON schema generation (required arrays, additionalProperties:false, $defs/$ref)

### Per-Call Structured Output Policy
- `WithStructuredOutputPolicy()` — Fluent one-shot policy override per request
- Presets: `StructuredOutputPolicy.NoRetry`, `StructuredOutputPolicy.Strict`
- Convenience: `WithNoRetryStructuredOutput()`, `WithStrictStructuredOutput()`

### Streaming Structured Output
- `BeginStream(prompt).WithStructuredOutput(policy).As&lt;T&gt;()` — Stream text chunks in real-time while getting a final deserialized object
- `Stream()` — Observe text chunks via `IAsyncEnumerable&lt;string&gt;` (optional, single-use)
- `Result` — Awaitable final deserialized object with auto-repair retries
- Works without `Stream()` — just `await run.Result` consumes internally
- Repair retries use non-streaming calls for efficiency

### Collection Support
- `List&lt;T&gt;`, `T[]`, `IReadOnlyList&lt;T&gt;` all work as type parameter for both `GetCompletionAsync&lt;T&gt;()` and streaming
- JSON array schema auto-generated, array extraction from markdown supported

## Supported Models

### OpenAI
- GPT-5, GPT-5 Mini, GPT-5 Nano, GPT-5 Chat Latest
- GPT-5.1
- GPT-5.2, GPT-5.2 Pro, GPT-5.2 Codex
- o3, o3-pro
- GPT-4.1, GPT-4.1 Mini, GPT-4.1 Nano
- GPT-4o, GPT-4o Mini, GPT-4 Vision

### Anthropic Claude
- Claude Opus 4.6, Opus 4.5, Opus 4.1, Opus 4
- Claude Sonnet 4.6, Sonnet 4.5, Sonnet 4
- Claude Haiku 4.5

### xAI Grok
- Grok 4, Grok 4.1 Fast
- Grok 3, Grok 3 Mini

### Google Gemini
- Gemini 2.5 Pro, Flash, Flash-Lite
- Gemini 3 Pro Preview, Flash Preview

### DeepSeek
- DeepSeek Chat, DeepSeek Reasoner

### Perplexity
- Sonar, Sonar Pro, Sonar Reasoning

## Documentation
- Basic Usage: https://github.com/AJ-comp/Mythosia.AI/wiki
- Advanced Features: https://github.com/AJ-comp/Mythosia.AI/wiki/Advanced-Features
- Release Notes: https://github.com/AJ-comp/Mythosia.AI/wiki/Release-Notes
- GitHub: https://github.com/AJ-comp/Mythosia.AI
		</Description>
		<PackageProjectUrl>https://github.com/AJ-comp/Mythosia.AI/tree/main/Mythosia.AI</PackageProjectUrl>
		<PackageReadmeFile>README.md</PackageReadmeFile>
		<Version>4.5.0</Version>
	</PropertyGroup>


	<ItemGroup>
		<PackageReference Include="Azure.AI.OpenAI" Version="2.1.0" />
		<PackageReference Include="Newtonsoft.Json" Version="13.0.4" />
		<PackageReference Include="NJsonSchema" Version="11.5.2" />
        <PackageReference Include="System.Threading.Channels" Version="10.0.3" />
        <PackageReference Include="TiktokenSharp" Version="1.2.1" />
	</ItemGroup>


	<ItemGroup>
	  <PackageReference Include="Mythosia" Version="1.4.0" />
	</ItemGroup>

	<ItemGroup>
	  <None Update="README.md">
	    <Pack>True</Pack>
	    <PackagePath>\</PackagePath>
	  </None>
	</ItemGroup>

	<ItemGroup>
	  <Folder Include="docs\" />
	</ItemGroup>

</Project>

